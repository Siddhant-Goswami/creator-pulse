#!/usr/bin/env python3
"""
Production Twitter Agent Runner - Automated execution with real API calls
"""

import asyncio
import json
import os
from datetime import datetime
from twitter_analyzer import TwitterCompetitorAnalyzer

async def run_production_analysis():
    """Run production analysis with real API calls"""
    
    print("ğŸ¦ Twitter Competitor Analyzer - PRODUCTION RUN")
    print("=" * 60)
    print("ğŸš€ Using real API keys for live Twitter data analysis")
    print()
    
    # Check API keys
    if not os.getenv('OPENROUTER_API_KEY'):
        print("âŒ OPENROUTER_API_KEY not set")
        return False
    
    if not os.getenv('APIFY_TOKEN'):
        print("âŒ APIFY_TOKEN not set")
        return False
    
    print("âœ… API keys configured")
    print()
    
    # Production configuration - analyzing real tech influencers
    config = {
        'user_username': 'elonmusk',  # High-profile user for competitor discovery
        'competitor_usernames': ['naval', 'sama', 'paulg', 'garyvee'],  # Manual competitors
        'tweets_per_competitor': 15,  # More tweets for better analysis
        'auto_discover': True,
        'min_competitors': 8
    }
    
    print("ğŸ“‹ Production Configuration:")
    print(f"  â€¢ Target user: @{config['user_username']}")
    print(f"  â€¢ Manual competitors: {', '.join('@' + c for c in config['competitor_usernames'])}")
    print(f"  â€¢ Auto-discover: {config['auto_discover']}")
    print(f"  â€¢ Tweets per competitor: {config['tweets_per_competitor']}")
    print(f"  â€¢ Minimum competitors: {config['min_competitors']}")
    print()
    
    try:
        analyzer = TwitterCompetitorAnalyzer()
        
        print("ğŸ” Starting Production Analysis...")
        print("=" * 40)
        
        # Build competitor list
        final_competitors = list(config['competitor_usernames'])
        
        # Auto-discover competitors if needed
        if config['auto_discover'] and config['user_username']:
            print(f"ğŸ” Auto-discovering competitors for @{config['user_username']}...")
            try:
                discovered = await analyzer.discover_competitors(
                    config['user_username'], 
                    config['min_competitors'] - len(final_competitors)
                )
                final_competitors.extend(discovered)
                print(f"âœ… Discovered {len(discovered)} additional competitors")
            except Exception as e:
                print(f"âš ï¸  Auto-discovery failed: {e}")
                print("ğŸ“ Continuing with manual competitor list...")
        
        # Remove duplicates and limit
        final_competitors = list(set(final_competitors))[:12]  # Limit for production
        
        if len(final_competitors) < 3:
            print("âŒ Need at least 3 competitors to analyze")
            return False
        
        print(f"\nğŸ“Š Final competitor list ({len(final_competitors)} accounts):")
        for i, competitor in enumerate(final_competitors, 1):
            print(f"  {i:2d}. @{competitor}")
        print()
        
        # Analyze each competitor's tweets
        competitor_tweets_data = {}
        successful_analyses = 0
        
        for i, username in enumerate(final_competitors):
            print(f"ğŸ“± [{i+1}/{len(final_competitors)}] Analyzing @{username}...")
            
            try:
                tweets = await analyzer.get_top_performing_tweets(username, config['tweets_per_competitor'])
                
                if tweets:
                    competitor_tweets_data[username] = tweets
                    avg_engagement = sum(t['engagement_score'] for t in tweets) / len(tweets)
                    successful_analyses += 1
                    
                    print(f"  âœ… Found {len(tweets)} tweets (avg engagement: {avg_engagement:.1f})")
                    
                    # Show top tweet preview
                    top_tweet = tweets[0]
                    text_preview = top_tweet.get('text', '')[:70] + "..." if len(top_tweet.get('text', '')) > 70 else top_tweet.get('text', '')
                    print(f"  ğŸ”¥ Top tweet: \"{text_preview}\"")
                    print(f"      ğŸ’« {top_tweet.get('likes', 0)} likes, {top_tweet.get('retweets', 0)} RTs, {top_tweet.get('replies', 0)} replies")
                else:
                    print(f"  âš ï¸  No tweets found")
                    
            except Exception as e:
                print(f"  âŒ Error: {str(e)}")
                continue
            
            # Rate limiting delay
            if i < len(final_competitors) - 1:
                print(f"  ğŸ˜´ Rate limiting pause...")
                await asyncio.sleep(3)
            
            print()
        
        if not competitor_tweets_data:
            print("âŒ No competitor data available")
            return False
        
        total_tweets = sum(len(tweets) for tweets in competitor_tweets_data.values())
        print(f"ğŸ“ˆ Production Analysis Summary:")
        print(f"  â€¢ Competitors successfully analyzed: {successful_analyses}/{len(final_competitors)}")
        print(f"  â€¢ Total tweets analyzed: {total_tweets}")
        print(f"  â€¢ Analysis success rate: {(successful_analyses/len(final_competitors)*100):.1f}%")
        print()
        
        # Analyze patterns
        print("ğŸ” Analyzing patterns across all competitor tweets...")
        patterns_analysis = await analyzer.analyze_tweet_patterns(competitor_tweets_data)
        
        # Display detailed insights
        print("\nğŸ“Š PRODUCTION PATTERN ANALYSIS")
        print("=" * 45)
        
        avg_engagement = patterns_analysis.get('avg_engagement_score', 0)
        print(f"ğŸ“ˆ Overall Performance: {avg_engagement:.1f} average engagement score")
        print()
        
        # Top hashtags
        top_hashtags = patterns_analysis.get('top_hashtags', [])[:10]
        if top_hashtags:
            print("ğŸ·ï¸  Most Effective Hashtags:")
            for i, hashtag_data in enumerate(top_hashtags, 1):
                print(f"  {i:2d}. #{hashtag_data['hashtag']:<20} ({hashtag_data['frequency']:2d} uses)")
            print()
        
        # Hook patterns
        hook_patterns = patterns_analysis.get('hook_patterns', {})
        top_hooks = hook_patterns.get('top_performing_hooks', [])[:8]
        if top_hooks:
            print("ğŸ£ Highest Performing Hook Examples:")
            for i, hook_data in enumerate(top_hooks, 1):
                hook_text = hook_data['hook'][:65] + "..." if len(hook_data['hook']) > 65 else hook_data['hook']
                print(f"  {i}. \"{hook_text}\"")
                print(f"     ğŸ’« {hook_data['engagement_score']:.1f} engagement (@{hook_data['competitor']})")
            print()
        
        # Hook starters
        hook_starters = hook_patterns.get('common_hook_starters', [])[:8]
        if hook_starters:
            print("ğŸš€ Most Successful Hook Starters:")
            for i, starter_data in enumerate(hook_starters, 1):
                print(f"  {i}. \"{starter_data['starter']}...\"")
                print(f"     ğŸ“Š {starter_data['avg_engagement']:.1f} avg engagement ({starter_data['count']} uses)")
            print()
        
        # Topic themes
        topics = patterns_analysis.get('topic_themes', [])[:12]
        if topics:
            print("ğŸ“ Trending Topic Themes:")
            # Display in rows of 4
            for i in range(0, len(topics), 4):
                row = topics[i:i+4]
                print(f"  â€¢ {' â€¢ '.join(row)}")
            print()
        
        # Posting optimization
        posting_patterns = patterns_analysis.get('posting_patterns', {})
        best_days = posting_patterns.get('best_days', [])[:5]
        if best_days:
            print("ğŸ“… Optimal Posting Schedule:")
            for day, score in best_days:
                print(f"  â€¢ {day:<10}: {score:.1f} avg engagement")
            print()
        
        # Generate AI-powered content ideas
        print("ğŸ¤– Generating AI-Powered Content Strategy...")
        print("=" * 50)
        
        try:
            content_ideas = await analyzer.generate_content_ideas(patterns_analysis, competitor_tweets_data)
            ai_generated = True
            print("âœ… AI content generation successful")
        except Exception as e:
            print(f"âš ï¸  AI generation failed: {e}")
            print("ğŸ“ Using fallback content generation...")
            content_ideas = analyzer._generate_fallback_ideas(patterns_analysis)
            ai_generated = False
        
        print()
        
        # Display content strategy
        tweet_ideas = content_ideas.get('tweet_ideas', [])
        if tweet_ideas:
            print(f"ğŸ¦ CONTENT IDEAS ({len(tweet_ideas)} suggestions):")
            print("-" * 50)
            for i, tweet in enumerate(tweet_ideas, 1):
                print(f"{i:2d}. {tweet}")
            print()
        
        hook_ideas = content_ideas.get('hook_ideas', [])
        if hook_ideas:
            print(f"ğŸ£ HOOK TEMPLATES ({len(hook_ideas)} patterns):")
            print("-" * 45)
            # Display in columns
            for i in range(0, len(hook_ideas), 2):
                if i + 1 < len(hook_ideas):
                    print(f"  â€¢ {hook_ideas[i]:<30} â€¢ {hook_ideas[i+1]}")
                else:
                    print(f"  â€¢ {hook_ideas[i]}")
            print()
        
        strategy_insights = content_ideas.get('strategy_insights', [])
        if strategy_insights:
            print(f"ğŸ“ˆ STRATEGIC RECOMMENDATIONS:")
            print("-" * 35)
            for i, insight in enumerate(strategy_insights, 1):
                print(f"{i}. {insight}")
            print()
        
        # Save comprehensive results
        results = {
            "production_run": True,
            "ai_generated": ai_generated,
            "timestamp": datetime.now().isoformat(),
            "config": config,
            "execution_summary": {
                "competitors_analyzed": successful_analyses,
                "total_competitors_attempted": len(final_competitors),
                "total_tweets_analyzed": total_tweets,
                "success_rate": successful_analyses / len(final_competitors),
                "avg_engagement_score": avg_engagement
            },
            "patterns_analysis": patterns_analysis,
            "content_ideas": content_ideas,
            "competitor_performance": {
                username: {
                    "tweets_analyzed": len(tweets),
                    "avg_engagement": sum(t['engagement_score'] for t in tweets) / len(tweets),
                    "top_performing_tweet": {
                        "text": tweets[0]['text'][:100] + "..." if len(tweets[0]['text']) > 100 else tweets[0]['text'],
                        "engagement_score": tweets[0]['engagement_score'],
                        "metrics": {
                            "likes": tweets[0]['likes'],
                            "retweets": tweets[0]['retweets'],
                            "replies": tweets[0]['replies']
                        }
                    } if tweets else None
                }
                for username, tweets in competitor_tweets_data.items()
            }
        }
        
        filename = f"production_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w') as f:
            json.dump(results, f, indent=2)
        
        print("ğŸ’¾ PRODUCTION RESULTS SUMMARY")
        print("=" * 35)
        print(f"ğŸ“„ Detailed results: {filename}")
        print(f"ğŸ¯ Analysis success rate: {(successful_analyses/len(final_competitors)*100):.1f}%")
        print(f"ğŸ“Š {total_tweets} tweets from {successful_analyses} competitors analyzed")
        print(f"ğŸ’¡ {len(tweet_ideas)} content ideas generated")
        print(f"ğŸ£ {len(hook_ideas)} hook templates provided")
        print(f"ğŸ¤– AI-powered generation: {'âœ… Yes' if ai_generated else 'âŒ Fallback used'}")
        
        print(f"\nâœ… PRODUCTION ANALYSIS COMPLETED!")
        print("=" * 50)
        print("ğŸš€ Key Insights:")
        print(f"   â€¢ Average engagement: {avg_engagement:.1f}")
        print(f"   â€¢ Top performing hook: \"{top_hooks[0]['hook'][:50]}...\"" if top_hooks else "   â€¢ No hook data available")
        print(f"   â€¢ Best posting day: {best_days[0][0]}" if best_days else "   â€¢ No timing data available")
        print(f"   â€¢ Most common theme: {topics[0]}" if topics else "   â€¢ No theme data available")
        
        return True
        
    except Exception as e:
        print(f"âŒ Production analysis failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Run the production analysis"""
    success = asyncio.run(run_production_analysis())
    return success

if __name__ == "__main__":
    main()